dag:

  # Config for DAG run
  dag_id: "Immigration_data_ETL"
  default_args:
    owner: "Rich"
    start_date: 2020-6-20
    end_date: 2020-6-20
    depends_on_past: False
    retries: 0
    catchup: False
    email: "richjdowney@gmail.com"
    email_on_failure: True
    email_on_retry: False
  schedule_interval: "@once"


emr:

  # AWS settings for EMR cluster
  Instances:
    Ec2KeyName: "spark-cluster"
    InstanceGroups:
    - Name: "Master node"
      InstanceRole: "MASTER"
      InstanceCount: 1
      InstanceType: "m5.xlarge"
    - Name: "Slave nodes"
      Market: "ON_DEMAND"
      InstanceRole: "CORE"
      InstanceType: "m5.xlarge"
      InstanceCount: 2
    KeepJobFlowAliveWhenNoSteps: True
    TerminationProtected: False
  JobFlowRole: "EMR_EC2_DefaultRole"
  ServiceRole: "EMR_DefaultRole"
  Name: "Immigration ETL"
  LogUri: "s3://immigration-data-etl/etl-log"
  ReleaseLabel: "emr-5.28.0"
  Configurations:
    - Classification: "spark-env"
      Configurations:
      - Classification: "export"
        Properties:
          PYSPARK_PYTHON: "/usr/bin/python3"
  BootstrapActions:
    - Name: "Install_Dependencies"
      ScriptBootstrapAction:
        Path: "s3://immigration-data-etl/bootstrap/install_dependencies.sh"
  StepConcurrencyLevel: 1

s3:

  # Config for s3
  Bucket: "immigration-data-etl"

  # Paths to runner files on s3(egg app, main runner)
  egg: "s3://immigration-data-etl/application/test_submit-0.1-py2.7.egg"
  runner: "s3://immigration-data-etl/application/spark_runner.py"

app:

  # Config for files related to running the Spark app on emr
  RootPath: "/home/ubuntu/immigration_code/"
  PathToBin: "/home/ubuntu/immigration_code/bin/"
  PathToEgg: "/home/ubuntu/immigration_code/dist/"
  PathToUtils: "/home/ubuntu/immigration_code/utils/"
  EggObject: "test_submit-0.1-py2.7.egg"
  RunnerObject: "spark_runner.py"
  DependenciesShell: "install_dependencies.sh"
  Requirements: "requirements.txt"

airflow:

  # Config for airflow defaults
  AwsCredentials: "aws_default"

input:

  # Config for input path and filenames
  InputPath: "s3://immigration-data-etl/"
  ImmigrationInput: "data-inputs/immigration_data/"
  AirportCodesInput: "data-inputs/airport-codes_csv.csv"
  CitiesInput: "data-inputs/us-cities-demographics.csv"
  CitResMapInput: "data-inputs/cit_res_mapping.csv"
  ModeMapInput: "data-inputs/mode_mapping.csv"
  StateMapInput: "data-inputs/state_mapping.csv"
  VisaMapInput: "data-inputs/visa_mapping.csv"
  PortMapInput: "data-inputs/port_mapping.txt"

staging:

  # Config for staging paths
  ImmigrationStaging: "s3://immigration-data-etl/staging-tables/immigration_staging"
  AirportStaging: "s3://immigration-data-etl/staging-tables/airport_staging"
  CitiesStaging: "s3://immigration-data-etl/staging-tables/city_staging"
  CitResMapStaging: "s3://immigration-data-etl/staging-tables/cit_res_map_staging"
  ModeMapStaging: "s3://immigration-data-etl/staging-tables/mode_staging"
  StateMapStaging: "s3://immigration-data-etl/staging-tables/state_staging"
  VisaMapStaging: "s3://immigration-data-etl/staging-tables/visa_staging"
  PortMapStaging: "s3://immigration-data-etl/staging-tables/port_staging"

adm:

  # Config for ADM paths
  Immigration: "s3://immigration-data-etl/adm/fact_immigration"
  Airport: "s3://immigration-data-etl/adm/dim_airport_codes"
  Cities: "s3://immigration-data-etl/adm/dim_city_demos"
  CitResMap: "s3://immigration-data-etl/adm/dim_cit_res"
  ModeMap: "s3://immigration-data-etl/adm/dim_mode"
  StateMap: "s3://immigration-data-etl/adm/dim_state"
  VisaMap: "s3://immigration-data-etl/adm/dim_visa"
  PortMap: "s3://immigration-data-etl/adm/dim_port"